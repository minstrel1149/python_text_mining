{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_metric\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AdamW\n",
    "from kobert_tokenizer import KoBERTTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>돈 들인건 티가 나지만 보는 내내 하품만</td>\n",
       "      <td>1</td>\n",
       "      <td>2018.10.29</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>나는 재밌게 봄</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.14</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>개연성은 무시해라 액션을 즐겨라 스타로드가 이끌어준다 각각의 영웅들을 즐겨라 그리고...</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.01</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>마지막에 누구한테 연락한거지? 궁금</td>\n",
       "      <td>9</td>\n",
       "      <td>2018.09.26</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이제는 지겨워서 못보겠다</td>\n",
       "      <td>5</td>\n",
       "      <td>2018.09.26</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating        date  \\\n",
       "0                             돈 들인건 티가 나지만 보는 내내 하품만       1  2018.10.29   \n",
       "1                                           나는 재밌게 봄      10  2018.10.14   \n",
       "2  개연성은 무시해라 액션을 즐겨라 스타로드가 이끌어준다 각각의 영웅들을 즐겨라 그리고...       8  2018.10.01   \n",
       "3                                마지막에 누구한테 연락한거지? 궁금       9  2018.09.26   \n",
       "4                                      이제는 지겨워서 못보겠다       5  2018.09.26   \n",
       "\n",
       "    title  \n",
       "0  인피니티 워  \n",
       "1  인피니티 워  \n",
       "2  인피니티 워  \n",
       "3  인피니티 워  \n",
       "4  인피니티 워  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/daum_movie_review.csv')\n",
    "df = df.loc[::5, :].reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       2\n",
       "2       2\n",
       "3       2\n",
       "4       1\n",
       "       ..\n",
       "2940    2\n",
       "2941    2\n",
       "2942    2\n",
       "2943    1\n",
       "2944    2\n",
       "Name: result, Length: 2945, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (df\n",
    " .assign(result=lambda df: np.where(df['rating'] <= 4, 'bad', np.where(df['rating'] >= 8, 'good', 'soso')))\n",
    " ['result']\n",
    " .replace({'bad':0, 'soso':1, 'good':2})\n",
    ")\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1545, 663, 737)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(df.review.tolist(), y.values, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.3, random_state=0)\n",
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_4256\\672663858.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric('accuracy')\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric('accuracy')\n",
    "\n",
    "def compute_metric(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "        super().__init__()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at skt/kobert-base-v1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "model = BertForSequenceClassification.from_pretrained('skt/kobert-base-v1', num_labels=3)\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "train_input = tokenizer(X_train, truncation=True, padding=True, return_tensors='pt')\n",
    "val_input = tokenizer(X_val, truncation=True, padding=True, return_tensors='pt')\n",
    "test_input = tokenizer(X_test, truncation=True, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = OurDataset(train_input, y_train)\n",
    "val_dataset = OurDataset(val_input, y_val)\n",
    "test_dataset = OurDataset(test_input, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1545\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 194\n",
      "  Number of trainable parameters = 92189187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2a3ca66dca4736882ef755c388c8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_4256\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 663\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7612f57e25c54097a683e53ae3ffa358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8689894676208496, 'eval_accuracy': 0.6636500754147813, 'eval_runtime': 355.1912, 'eval_samples_per_second': 1.867, 'eval_steps_per_second': 0.118, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_4256\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 663\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3fcbc161ca4baa97a31340ee3e10f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8431844115257263, 'eval_accuracy': 0.6621417797888386, 'eval_runtime': 341.2687, 'eval_samples_per_second': 1.943, 'eval_steps_per_second': 0.123, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_4256\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 663\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820af53c5ddc4c75a5a68b6091fb361a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7212477326393127, 'eval_accuracy': 0.6998491704374057, 'eval_runtime': 334.7483, 'eval_samples_per_second': 1.981, 'eval_steps_per_second': 0.125, 'epoch': 1.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_4256\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 663\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3456dfb57848c8bd742617d0c07eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6862955689430237, 'eval_accuracy': 0.7088989441930619, 'eval_runtime': 347.3004, 'eval_samples_per_second': 1.909, 'eval_steps_per_second': 0.121, 'epoch': 1.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_4256\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 5978.2802, 'train_samples_per_second': 0.517, 'train_steps_per_second': 0.032, 'train_loss': 0.8000916943107683, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=194, training_loss=0.8000916943107683, metrics={'train_runtime': 5978.2802, 'train_samples_per_second': 0.517, 'train_steps_per_second': 0.032, 'train_loss': 0.8000916943107683, 'epoch': 2.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(output_dir='./results', num_train_epochs=2,\n",
    "                                  evaluation_strategy='steps', eval_steps=40,\n",
    "                                  per_device_train_batch_size=16, per_device_eval_batch_size=16,\n",
    "                                  warmup_steps=100, weight_decay=0.01)\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, eval_dataset=val_dataset, compute_metrics=compute_metric)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 737\n",
      "  Batch size = 16\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_4256\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f217cde801bd444eb2e39e8a7084fb4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6582435965538025,\n",
       " 'eval_accuracy': 0.723202170963365,\n",
       " 'eval_runtime': 444.0189,\n",
       " 'eval_samples_per_second': 1.66,\n",
       " 'eval_steps_per_second': 0.106,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 737\n",
      "  Batch size = 16\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_4256\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b436437d7b54ddc92c64e74897a52ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.08356023, -0.34667933,  0.34367242],\n",
       "       [-1.3751858 , -1.039848  ,  2.2063167 ],\n",
       "       [-1.2503979 , -0.77620715,  2.0081325 ],\n",
       "       ...,\n",
       "       [ 0.13815361, -0.16921851,  0.06255788],\n",
       "       [-0.8249176 , -0.6109066 ,  1.369531  ],\n",
       "       [-1.4625283 , -0.8776499 ,  2.1051786 ]], dtype=float32), label_ids=array([0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 1, 0, 0, 2, 2, 2, 2,\n",
       "       0, 0, 1, 0, 2, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 2, 2, 2, 2, 1, 2, 2,\n",
       "       2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 0, 1, 0, 0, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       0, 1, 0, 0, 1, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2,\n",
       "       2, 2, 0, 0, 0, 2, 2, 0, 1, 2, 0, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0,\n",
       "       2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 1, 0, 2, 1, 2, 2, 2, 2, 0, 1, 0,\n",
       "       2, 2, 1, 2, 0, 0, 2, 2, 0, 2, 1, 2, 2, 0, 1, 0, 2, 2, 2, 1, 1, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0,\n",
       "       2, 0, 2, 2, 1, 2, 2, 1, 2, 2, 0, 2, 0, 1, 2, 2, 2, 2, 2, 0, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 2, 2, 2, 2, 0, 2, 2, 0, 0, 1,\n",
       "       2, 2, 0, 2, 2, 2, 2, 1, 0, 0, 0, 2, 2, 1, 0, 1, 2, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 0, 2, 2, 1, 0, 0, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2,\n",
       "       0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 0, 1, 0, 2, 2, 2, 2, 0, 0, 1, 2, 1, 0, 0, 2, 0, 2, 2,\n",
       "       2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 0, 2, 2,\n",
       "       1, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2,\n",
       "       1, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "       0, 2, 1, 2, 2, 2, 0, 0, 1, 1, 2, 1, 1, 0, 0, 2, 0, 1, 0, 2, 1, 1,\n",
       "       0, 0, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2,\n",
       "       2, 0, 1, 2, 0, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 0, 1, 2, 0, 2, 2, 2,\n",
       "       2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 1, 1, 1,\n",
       "       0, 2, 1, 1, 0, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,\n",
       "       2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 1, 1, 2, 2, 2, 1, 2, 2, 0, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 0, 1, 0, 0, 1, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2,\n",
       "       2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 1, 2, 1, 0, 2, 2, 1, 0, 2, 1, 1,\n",
       "       2, 1, 0, 2, 0, 0, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 0, 2,\n",
       "       2, 2, 2, 0, 1, 2, 2, 1, 2, 2, 0, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0,\n",
       "       2, 2, 0, 0, 1, 2, 0, 0, 0, 2, 2, 0, 0, 2, 2, 2, 1, 0, 0, 2, 0, 1,\n",
       "       0, 2, 0, 1, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 0,\n",
       "       2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 0, 0, 2, 2, 2, 2,\n",
       "       2, 2, 2, 1, 2, 0, 2, 2, 2, 1, 2, 1, 2, 0, 2, 2, 0, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 1, 2, 1, 2, 2, 0, 2, 1, 2, 2,\n",
       "       2, 2, 0, 1, 2, 1, 0, 2, 2, 2, 2], dtype=int64), metrics={'test_loss': 0.6582435965538025, 'test_accuracy': 0.723202170963365, 'test_runtime': 445.8939, 'test_samples_per_second': 1.653, 'test_steps_per_second': 0.105})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = trainer.predict(test_dataset=test_dataset)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(737,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.label_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
