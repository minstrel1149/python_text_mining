{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4ebfa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ddd5cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "232ddfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 POSITIVE 0.9998812675476074\n"
     ]
    }
   ],
   "source": [
    "clf = pipeline('sentiment-analysis', framework='pt')\n",
    "result = clf('what a beautiful day!')[0]\n",
    "print(clf.device, result['label'], result['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecb66734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice was beginning to get very tired of sitting by her sister on the bank,  she started to feel like she was doing something wrong.  Then there was the time of day... the sun was out and the wind was blowing.  (She was still in the sunshade for lunch!)  When she finally got her morning light out she started to feel like she was on a roll.  She was really tired and tired, and started to feel like she was going to die.  She was dying as soon as she was exposed to the sun.  (She was dying as soon as she was exposed to the sun!)  She was tired, hungry and tired.  She was hungry and hungry.  She was dying as soon as she was exposed to the sun.\n",
      "We all know there is a lot of stress in our lives and it makes us really sick to think so much about it.  It can be scary and it can be very hard to understand.  It can be a really tough time for you.  You really need to get over it and get over the thing.  If you have not, then you're just going to become a victim of someone who cares too much and is really, really bad at doing other things.  There\n"
     ]
    }
   ],
   "source": [
    "text_gen = pipeline('text-generation', framework='pt')\n",
    "result = text_gen('Alice was beginning to get very tired of sitting by her sister on the bank, ')\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81eb4aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-cased-finetuned-mrpc'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cba961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = \"She angered me with her inappropriate comments, rumor-spreading, and disrespectfulness at the formal dinner table\"\n",
    "target_sequence = \"She made me angry when she was rude at dinner\"\n",
    "target_sequence_2 = \"The boy quickly ran across the finish line, seizing yet another victory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aede807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no: 29%\n",
      "yes: 71%\n",
      "{'input_ids': tensor([[  101,  1153, 22296,  1143,  1114,  1123, 17073,  7640,   117, 24206,\n",
      "           118,  9243,   117,  1105,  4267,  1116,  4894, 26426, 21047,  1120,\n",
      "          1103,  4698,  4014,  1952,   102,  1153,  1189,  1143,  4259,  1165,\n",
      "          1131,  1108, 14708,  1120,  4014,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
      "tensor([[0.1998, 1.0848]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "[0.2921431362628937, 0.7078568935394287]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(input_sentence, target_sequence, return_tensors='pt').to(device)\n",
    "logits = model(**tokens).logits\n",
    "results = torch.softmax(logits, dim=1).tolist()[0]\n",
    "for i, label in enumerate(['no', 'yes']):\n",
    "    print(f'{label}: {int(round(results[i] * 100))}%')\n",
    "\n",
    "print(tokens)\n",
    "print(logits)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f4400e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no: 95%\n",
      "yes: 5%\n",
      "{'input_ids': tensor([[  101,  1153, 22296,  1143,  1114,  1123, 17073,  7640,   117, 24206,\n",
      "           118,  9243,   117,  1105,  4267,  1116,  4894, 26426, 21047,  1120,\n",
      "          1103,  4698,  4014,  1952,   102,  1109,  2298,  1976,  1868,  1506,\n",
      "          1103,  3146,  1413,   117, 14516,  4404,  1870,  1330,  2681,   102]],\n",
      "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
      "tensor([[ 0.6605, -2.2799]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "[0.9498079419136047, 0.05019203573465347]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(input_sentence, target_sequence_2, return_tensors='pt').to(device)\n",
    "logits = model(**tokens).logits\n",
    "results = torch.softmax(logits, dim=1).tolist()[0]\n",
    "for i, label in enumerate(['no', 'yes']):\n",
    "    print(f'{label}: {int(round(results[i] * 100))}%')\n",
    "\n",
    "print(tokens)\n",
    "print(logits)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d07030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileids = movie_reviews.fileids()\n",
    "reviews = [movie_reviews.raw(fileid) for fileid in fileids]\n",
    "categories = [movie_reviews.categories(fileid)[0] for fileid in fileids]\n",
    "label_dict = {'pos':1, 'neg':0}\n",
    "y = np.array([label_dict[c] for c in categories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "999262aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reviews, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3637189",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9e98598",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "y_pred = []\n",
    "\n",
    "num_batch = len(y_test) // batch_size\n",
    "\n",
    "for i in range(num_batch):\n",
    "    inputs = tokenizer(X_test[i*batch_size:(i+1)*batch_size], truncation=True, padding=True, return_tensors='pt').to(device)\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "    pred = torch.softmax(logits, dim=-1)\n",
    "    results = pred.cpu().detach().numpy().argmax(axis=1)\n",
    "\n",
    "    y_pred.extend(results.tolist())\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c081393b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8425\n"
     ]
    }
   ],
   "source": [
    "score = sum(y_test == np.array(y_pred)) / len(y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca5d235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
