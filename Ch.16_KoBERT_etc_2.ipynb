{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "075799f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Coding\\Local\\python_text_mining\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88df75fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Coding\\\\Local\\\\exercisebook_large_data\\\\Transformers\\\\results'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_path = str(Path.cwd().parent / 'exercisebook_large_data' / 'Transformers' / 'results')\n",
    "result_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d16e6040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f25d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>돈 들인건 티가 나지만 보는 내내 하품만</td>\n",
       "      <td>1</td>\n",
       "      <td>2018.10.29</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.26</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.24</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이 정도면 볼만하다고 할 수 있음!</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.22</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>재미있다</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.20</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating        date  \\\n",
       "0                             돈 들인건 티가 나지만 보는 내내 하품만       1  2018.10.29   \n",
       "1       몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.      10  2018.10.26   \n",
       "2  이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...       8  2018.10.24   \n",
       "3                                이 정도면 볼만하다고 할 수 있음!       8  2018.10.22   \n",
       "4                                               재미있다      10  2018.10.20   \n",
       "\n",
       "    title  \n",
       "0  인피니티 워  \n",
       "1  인피니티 워  \n",
       "2  인피니티 워  \n",
       "3  인피니티 워  \n",
       "4  인피니티 워  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/daum_movie_review.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7089790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        2\n",
      "2        2\n",
      "3        2\n",
      "4        2\n",
      "        ..\n",
      "14720    2\n",
      "14721    1\n",
      "14722    2\n",
      "14723    2\n",
      "14724    2\n",
      "Name: result, Length: 14725, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21900\\4122692479.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({'bad':0, 'soso':1, 'good':2})\n"
     ]
    }
   ],
   "source": [
    "y = (df\n",
    " .assign(result=lambda df: np.where(df['rating'] <= 4, 'bad', np.where(df['rating'] >= 8, 'good', 'soso')))\n",
    " ['result']\n",
    " .replace({'bad':0, 'soso':1, 'good':2})\n",
    ")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c341f5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7730, 3313, 3682)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(df.review.tolist(), y.values, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.3, random_state=0)\n",
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8b3416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "229e5ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "        super().__init__()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5b77f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'monologg/kobert'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60dc774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = tokenizer(X_train, truncation=True, padding=True, return_tensors='pt')\n",
    "val_input = tokenizer(X_val, truncation=True, padding=True, return_tensors='pt')\n",
    "test_input = tokenizer(X_test, truncation=True, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea16e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = OurDataset(train_input, y_train)\n",
    "val_dataset = OurDataset(val_input, y_val)\n",
    "test_dataset = OurDataset(test_input, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef4da8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=result_path,\n",
    "    logging_dir='./logs',\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16, per_device_eval_batch_size=16,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    gradient_accumulation_steps=4,\n",
    "    #bf16=True,\n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c365bd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21900\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1210' max='1210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1210/1210 08:57, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.868343</td>\n",
       "      <td>0.657108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.867306</td>\n",
       "      <td>0.657108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.882157</td>\n",
       "      <td>0.657108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.858246</td>\n",
       "      <td>0.654694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.878900</td>\n",
       "      <td>0.843399</td>\n",
       "      <td>0.656505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.878900</td>\n",
       "      <td>0.846599</td>\n",
       "      <td>0.657108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.878900</td>\n",
       "      <td>0.832626</td>\n",
       "      <td>0.658316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.878900</td>\n",
       "      <td>0.840471</td>\n",
       "      <td>0.650166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.878900</td>\n",
       "      <td>0.843907</td>\n",
       "      <td>0.666465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.809000</td>\n",
       "      <td>0.848278</td>\n",
       "      <td>0.662843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.809000</td>\n",
       "      <td>0.841297</td>\n",
       "      <td>0.667975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.809000</td>\n",
       "      <td>0.850177</td>\n",
       "      <td>0.666465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21900\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21900\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21900\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21900\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21900\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21900\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21900\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21900\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21900\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21900\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21900\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21900\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1210, training_loss=0.8247725053267045, metrics={'train_runtime': 537.8355, 'train_samples_per_second': 143.724, 'train_steps_per_second': 2.25, 'total_flos': 6276385578279600.0, 'train_loss': 0.8247725053267045, 'epoch': 10.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89648f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21900\\1541230738.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='231' max='231' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [231/231 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8424486517906189,\n",
       " 'eval_accuracy': 0.6662140141227594,\n",
       " 'eval_runtime': 7.2284,\n",
       " 'eval_samples_per_second': 509.379,\n",
       " 'eval_steps_per_second': 31.957,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff866bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd421824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
