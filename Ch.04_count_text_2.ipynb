{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fba13c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews, stopwords\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77dc722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "583c67ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', 'neg/cv003_12683.txt', 'neg/cv004_12641.txt', 'neg/cv005_29357.txt', 'neg/cv006_17022.txt', 'neg/cv007_4992.txt', 'neg/cv008_29326.txt', 'neg/cv009_29417.txt']\n",
      "plot : two teen couples go to a church party , drink and then drive . \n",
      "they get into an accident . \n",
      "\n",
      "[['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.'], ['they', 'get', 'into', 'an', 'accident', '.']]\n",
      "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an']\n"
     ]
    }
   ],
   "source": [
    "print(len(movie_reviews.fileids()))\n",
    "print(movie_reviews.fileids()[:10])\n",
    "fileid = movie_reviews.fileids()[0]\n",
    "print(movie_reviews.raw(fileid)[:100])\n",
    "print(movie_reviews.sents(fileid)[:2])\n",
    "print(movie_reviews.words(fileid)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d77b3735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot : two teen couples go to a church party , drink and then drive . \n",
      "they get into an accident . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids()]\n",
    "print(reviews[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc2ca0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(max_features=1000)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(max_features=1000)\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "915b9d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10' 'ability' 'able' 'about' 'above' 'absolutely' 'across' 'act'\n",
      " 'acting' 'action' 'actor' 'actors' 'actress' 'actual' 'actually' 'add'\n",
      " 'after' 'again' 'against' 'age']\n",
      "<class 'scipy.sparse._csr.csr_matrix'> (2000, 1000)\n"
     ]
    }
   ],
   "source": [
    "reviews_cv = cv.fit_transform(reviews)\n",
    "print(cv.get_feature_names_out()[:20])\n",
    "print(type(reviews_cv), reviews_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "498060aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10: 10, ability: 0, able: 0, about: 2, above: 0, absolutely: 0, across: 0, act: 0, acting: 0, action: 0, actor: 0, actors: 1, actress: 0, actual: 0, actually: 2, add: 0, after: 2, again: 2, against: 0, age: 0, "
     ]
    }
   ],
   "source": [
    "for word, count in zip(cv.get_feature_names_out()[:20], reviews_cv[0].toarray()[0, :20]):\n",
    "    print(f'{word}: {count}', end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27b0546c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>돈 들인건 티가 나지만 보는 내내 하품만</td>\n",
       "      <td>1</td>\n",
       "      <td>2018.10.29</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.26</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.24</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이 정도면 볼만하다고 할 수 있음!</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.22</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>재미있다</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.20</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating        date  \\\n",
       "0                             돈 들인건 티가 나지만 보는 내내 하품만       1  2018.10.29   \n",
       "1       몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.      10  2018.10.26   \n",
       "2  이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...       8  2018.10.24   \n",
       "3                                이 정도면 볼만하다고 할 수 있음!       8  2018.10.22   \n",
       "4                                               재미있다      10  2018.10.20   \n",
       "\n",
       "    title  \n",
       "0  인피니티 워  \n",
       "1  인피니티 워  \n",
       "2  인피니티 워  \n",
       "3  인피니티 워  \n",
       "4  인피니티 워  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/daum_movie_review.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98cd528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['몰입', '할수밖에', '없다', '.', '어렵게', '생각', '할', '필요없다', '.', '내', '가', '전투', '에', '참여', '한', '듯', '손', '에', '땀', '이남', '.']\n",
      "['몰입', '생각', '내', '전투', '참여', '듯', '손', '땀', '이남']\n",
      "[('몰입', 'Noun'), ('할수밖에', 'Verb'), ('없다', 'Adjective'), ('.', 'Punctuation'), ('어렵게', 'Adjective'), ('생각', 'Noun'), ('할', 'Verb'), ('필요없다', 'Adjective'), ('.', 'Punctuation'), ('내', 'Noun'), ('가', 'Josa'), ('전투', 'Noun'), ('에', 'Josa'), ('참여', 'Noun'), ('한', 'Determiner'), ('듯', 'Noun'), ('손', 'Noun'), ('에', 'Josa'), ('땀', 'Noun'), ('이남', 'Noun'), ('.', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "print(okt.morphs(df['review'][1]))\n",
    "print(okt.nouns(df['review'][1]))\n",
    "print(okt.pos(df['review'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "844fc0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(doc):\n",
    "    return [token for token, pos in okt.pos(doc) if pos in ['Noun', 'Verb', 'Adjective']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27b2b680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['몰입', '할수밖에', '없다', '어렵게', '생각', '할', '필요없다', '내', '전투', '참여', '듯', '손', '땀', '이남']\n"
     ]
    }
   ],
   "source": [
    "print(my_tokenizer(df['review'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0609351e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Coding\\Local\\python_text_mining\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['가' '가는' '가는줄' '가면' '가서' '가슴' '가장' '가족' '가족영화' '가지' '가치' '각색' '간' '간다'\n",
      " '간만' '갈' '갈수록' '감' '감독' '감동' '감사' '감사합니다' '감상' '감성' '감정' '감탄' '갑자기' '갔는데'\n",
      " '갔다' '갔다가' '강' '강철' '강추' '같고' '같네요' '같다' '같습니다' '같아' '같아요' '같은' '같은데'\n",
      " '같음' '개' '개그' '개봉' '개연' '개인' '거' '거기' '거리' '거의' '걱정' '건' '건가' '건지' '걸'\n",
      " '겁니다' '것' '게' '겨울왕국' '결론' '결말' '경찰' '경험' '계속' '고' '고맙습니다' '고민' '고생' '곤지암'\n",
      " '곳' '공감' '공포' '공포영화' '과' '과거' '관' '관객' '관객수' '관람' '광주' '괜찮은' '교훈' '구성'\n",
      " '국내' '국민' '군인' '군함도' '굿' '권선' '귀신' '귀인' '그' '그것' '그게' '그날' '그냥' '그닥'\n",
      " '그대로' '그때']\n"
     ]
    }
   ],
   "source": [
    "daum_cv = CountVectorizer(max_features=1000, tokenizer=my_tokenizer)\n",
    "daum_DTM = daum_cv.fit_transform(df['review'])\n",
    "print(daum_cv.get_feature_names_out()[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61e85da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.9406850065028822), np.float64(0.8449222207991461), np.float64(0.8348806607881823), np.float64(0.8326052445239385), np.float64(0.8315967745603229), np.float64(0.8273858498106984), np.float64(0.8245530382632896), np.float64(0.8219627744618032), np.float64(0.820420990734705), np.float64(0.8203286730382311)]\n",
      "0\n",
      "[   0  126 1501  100 1846  882 1560 1110    9 1570]\n"
     ]
    }
   ],
   "source": [
    "start = len(reviews[0]) // 2\n",
    "source = reviews[0][-start:]\n",
    "source_cv = cv.transform([source])\n",
    "sim_result = cosine_similarity(source_cv, reviews_cv)\n",
    "print(sorted(sim_result[0], reverse=True)[:10])\n",
    "print(np.argmax(sim_result[0]))\n",
    "print((-sim_result[0]).argsort()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9253fb96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
