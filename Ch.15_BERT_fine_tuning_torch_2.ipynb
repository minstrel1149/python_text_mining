{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac658b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from transformers import BertModel, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb84fc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Coding\\\\Local\\\\exercisebook_large_data\\\\Transformers\\\\results'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_path = str(Path.cwd().parent / 'exercisebook_large_data' / 'Transformers' / 'results')\n",
    "result_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c34779e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16cb45ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileids = movie_reviews.fileids()\n",
    "reviews = [movie_reviews.raw(fileid) for fileid in fileids]\n",
    "categories = [movie_reviews.categories(fileid)[0] for fileid in fileids] \n",
    "\n",
    "label_dict = {'pos':1, 'neg':0}\n",
    "y = [label_dict[c] for c in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef0cd140",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(reviews, y, test_size=0.2, random_state=7)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3142a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "bert_model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7366f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "train_input = tokenizer(X_train, truncation=True, padding=True, return_tensors='pt')\n",
    "val_input = tokenizer(X_val, truncation=True, padding=True, return_tensors='pt')\n",
    "test_input = tokenizer(X_test, truncation=True, padding=True, return_tensors='pt')\n",
    "print(list(train_input.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb2bb2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e0c3c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = OurDataset(train_input, y_train)\n",
    "val_dataset = OurDataset(val_input, y_val)\n",
    "test_dataset = OurDataset(test_input, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4544ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    pred = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=pred, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "158fb138",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=16)\n",
    "val_loader = DataLoader(val_dataset, shuffle=True, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "989054c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, pretrained_model, token_size, num_labels):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.token_size = token_size\n",
    "        self.num_labels = num_labels\n",
    "        self.pretrained_model = pretrained_model\n",
    "        \n",
    "        self.classifier = nn.Linear(self.token_size, self.num_labels)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        outputs = self.pretrained_model(**inputs)\n",
    "        bert_clf_token = outputs.last_hidden_state[:, 0, :]\n",
    "        return self.classifier(bert_clf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07309247",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(bert_model, num_labels=2, token_size=bert_model.config.hidden_size)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d02b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = AdamW(model.parameters(), lr=1e-3)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85bcdc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_1996\\475304883.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_1996\\4194622315.py:20: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\autograd\\generated\\python_variable_methods.cpp:836.)\n",
      "  total_epoch_loss += float(loss)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss for epoch 1: 0.8781\n",
      "Avg loss for epoch 2: 0.7066\n",
      "Avg loss for epoch 3: 0.7194\n",
      "Avg loss for epoch 4: 0.6954\n",
      "Avg loss for epoch 5: 0.6956\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_epoch_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = loss_function(outputs, F.one_hot(labels, num_classes=2).float())\n",
    "\n",
    "        if (step+1) % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1}, batch {step+1}, loss {loss:.4f}\")\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        total_epoch_loss += float(loss)\n",
    "\n",
    "    avg_epoch_loss = total_epoch_loss / len(train_loader)\n",
    "    print(f\"Avg loss for epoch {epoch+1}: {avg_epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9d4d8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_1996\\475304883.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.495}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "for batch in test_loader:\n",
    "    inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "    labels = batch['labels'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "    predictions = torch.argmax(outputs, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=labels)\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bae6a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c466a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음.. accuracy가 낮게 나오는데 어차피 쓸 일 없으려나? Trainer 위주로 활용 예정"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
