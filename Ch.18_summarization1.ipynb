{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Text mining involves deriving high-quality information from text . Written resources may include websites, books, emails, reviews, and articles . Text mining is similar to text analytics . It involves the discovery by computer of new, previously unknown information by automatically extracting information from different written resources .'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline('summarization')\n",
    "text = '''Text mining, also referred to as text data mining (abbr.: TDM), similar to text analytics, \n",
    "        is the process of deriving high-quality information from text. It involves \n",
    "        \"the discovery by computer of new, previously unknown information, \n",
    "        by automatically extracting information from different written resources.\" \n",
    "        Written resources may include websites, books, emails, reviews, and articles. \n",
    "        High-quality information is typically obtained by devising patterns and trends \n",
    "        by means such as statistical pattern learning. According to Hotho et al. (2005)\n",
    "        we can distinguish between three different perspectives of text mining: \n",
    "        information extraction, data mining, and a KDD (Knowledge Discovery in Databases) process.''' \n",
    "result = summarizer(text)\n",
    "result[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('t5-small', model_max_length=512)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('t5-small')\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(transformers.models.t5.tokenization_t5_fast.T5TokenizerFast,\n",
       " transformers.models.t5.modeling_t5.T5ForConditionalGeneration)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer), type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_text = text.strip().replace('\\n', '')\n",
    "input_text = 'summarize: ' + preprocess_text\n",
    "tokenized_text = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "summary_ids = model.generate(tokenized_text, num_beams=4, no_repeat_ngram_size=3,\n",
    "                             min_length=30, max_length=200, early_stopping=True)\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text data mining is the process of deriving high-quality information from text. it involves the discovery by computer of new, previously unknown information. a KDD (Knowledge Discovery in Databases) process is similar to text analytics.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[21603,    10,  5027,  5558,     6,    92,     3,  4822,    12,    38,\n",
       "           1499,   331,  5558,    41, 12982,    52,     5,    10,   332,  7407,\n",
       "            201,  1126,    12,  1499,  9952,     6,    19,     8,   433,    13,\n",
       "             20,  5927,    53,   306,    18,  4497,   251,    45,  1499,     5,\n",
       "             94,  5806,    96,   532,  9087,    57,  1218,    13,   126,     6,\n",
       "           3150,  7752,   251,     6,    57,  3269,  5819,    53,   251,    45,\n",
       "            315,  1545,  1438,   535, 22812,  1438,   164,   560,  3395,     6,\n",
       "           1335,     6,  7594,     6,  2456,     6,    11,  2984,     5,  1592,\n",
       "             18,  4497,   251,    19,  3115,  5105,    57, 13282,    53,  4264,\n",
       "             11,  5001,    57,   598,   224,    38, 11775,  3275,  1036,     5,\n",
       "           2150,    12,  1546,   189,    32,     3,    15,    17,   491,     5,\n",
       "              3, 29495,    62,    54, 15849,   344,   386,   315, 14013,    13,\n",
       "           1499,  5558,    10,   251, 16629,     6,   331,  5558,     6,    11,\n",
       "              3,     9,   480, 11253,    41,   439,  7651, 13553, 19499,    16,\n",
       "          20230,     7,    61,   433,     5,     1]]),\n",
       " tensor([[    0,  1499,   331,  5558,    19,     8,   433,    13,    20,  5927,\n",
       "             53,   306,    18,  4497,   251,    45,  1499,     3,     5,    34,\n",
       "           5806,     8,  9087,    57,  1218,    13,   126,     6,  3150,  7752,\n",
       "            251,     3,     5,     3,     9,   480, 11253,    41,   439,  7651,\n",
       "          13553, 19499,    16, 20230,     7,    61,   433,    19,  1126,    12,\n",
       "           1499,  9952,     3,     5,     1]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text, summary_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das ist gut.\n"
     ]
    }
   ],
   "source": [
    "input_text = 'translate english to german: That is good'\n",
    "tokenized_text = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "summary_ids = model.generate(tokenized_text, num_beams=4, no_repeat_ngram_size=3,\n",
    "                             max_length=200, early_stopping=True)\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5TokenizerFast.from_pretrained('t5-small', model_max_length=1024)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''The Inflation Reduction Act lowers prescription drug costs, health care costs, \n",
    "and energy costs. It's the most aggressive action on tackling the climate crisis in American history, \n",
    "which will lift up American workers and create good-paying, union jobs across the country. \n",
    "It'll lower the deficit and ask the ultra-wealthy and corporations to pay their fair share. \n",
    "And no one making under $400,000 per year will pay a penny more in taxes.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_text = text.strip().replace('\\n', '')\n",
    "input_text = 'summarize: ' + preprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs. it's the most aggressive action on tackling the climate crisis in history. no one making under $400,000 per year will pay a penny more in taxes.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "summary_ids = model.generate(tokenized_text,\n",
    "                             num_beams=4, no_repeat_ngram_size=3,\n",
    "                             min_length=30, max_length=100, early_stopping=True)\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text \n",
      " The people of the State of California do enact as follows:\n",
      "\n",
      "\n",
      "SECTION 1.\n",
      "(a) It is the intent of the Legislature in enacting this act that cost, quality, and equity data be made available and to encourage health care service plans, health insurers, and providers to develop innovative approaches, services, and programs that may have the potential to deliver health care that is both cost effective and responsive to the needs of all enrollees, including recognizing the diversity of California and the impact of social determinants of health.\n",
      "(b) It is further the intent of the Legislature that a cost, quality, and equity data atlas be utilized in California to inform efforts to:\n",
      "(1) Assess California health care needs and available resources.\n",
      "(2) Contain the cost of health care services and coverage.\n",
      "(3) Improve the quality and medical appropriateness of health care.\n",
      "(4) Eliminate or reduce health disparities and address the social determinants of health.\n",
      "(5) Increase the transparency of health care costs and the relative efficiency with which care is delivered.\n",
      "(6) Promote the use of disease management, wellness, prevention, and other innovative programs to keep people healthy, reduce disparities and costs, increase competition, and improve health outcomes for all populations.\n",
      "(7) Assess the value and encourage the efficient utilization of prescription drugs and technology.\n",
      "(8) Reduce unnecessary, inappropriate, and wasteful health care.\n",
      "(9) Educate consumers in the use of health care information.\n",
      "SEC. 2.\n",
      "The heading of Chapter 8 (formerly commencing with Section 127670) of Part 2 of Division 107 of the Health and Safety Code, as amended by Section 230 of Chapter 183 of the Statutes of 2004, is repealed.\n",
      "SEC. 3.\n",
      "Chapter 8 (commencing with Section 127670) is added to Part 2 of Division 107 of the Health and Safety Code, to read:\n",
      "CHAPTER  8. California Health Care Cost, Quality, and Equity Data Atlas\n",
      "127670.\n",
      "(a) The California Health and Human Services Agency shall research the options for developing a cost, quality, and equity data atlas that is consistent with paragraph (9) of subdivision (b) of Section 56.10 of the Civil Code. This research shall include all of the following:\n",
      "(1) Identification of key data submitters, including health care service plans, specialized health care service plans, insurers licensed to provide health insurance, as defined in Section 106 of the Insurance Code, suppliers, as defined in paragraph (3) of subdivision (b) of Section 1367.50, providers, as defined in paragraph (2) of subdivision (b) of Section 1367.50, self-insured employers, multiemployer self-insured plans that are responsible for paying for health care services provided to beneficiaries, and trust administrators for multiemployer self-insured plans.\n",
      "(2) A comparative analysis of potential models used in other states and an assessment of the extent to which information in addition to the following should be included in the cost, quality, and equity data atlas:\n",
      "(A) Data from the health care service plans’ and insurers’ medical, dental, and pharmacy claims or, in the case of entities that do not use claims data, including, but not limited to, integrated delivery systems, encounter data consistent with the core set of data elements for data submission proposed by the All-Payer Claims Database Council, the University of New Hampshire, and the National Association of Health Data Organizations.\n",
      "(B) Pricing information for health care items, services, and medical and surgical episodes of care gathered from allowed charges for covered health care items and services or, in the case of entities that do not use or produce individual claims, price information that is the best possible proxy to pricing information for health care items, services, and medical and surgical episodes of care available in lieu of actual cost data to allow for meaningful comparisons of provider prices and treatment costs.\n",
      "(C) Information sufficient to determine the impacts of social determinants of health, including age, gender, race, ethnicity, limited English proficiency, sexual orientation and gender identity, ZIP Code, and any other factors for which there is peer-reviewed evidence.\n",
      "(D) Clinical data from health care service plans, integrated delivery systems, hospitals, and clinics, or any combination thereof, that is not included in the core set of data elements for data submission proposed by the All-Payer Claims Database Council and the National Association of Health Data Organizations.\n",
      "(3) An assessment of types of governance structures that incorporate representatives of health care stakeholders and experts, including, but not limited to, representatives of data submitters and representatives of purchasers, such as businesses, organized labor, and consumers.\n",
      "(4) Recommendations on potential funding approaches to support the activities of the cost, quality, and equity data atlas that recognize federal and state confidentiality of medical information laws.\n",
      "(5) An assessment on the extent to which the cost, quality, and equity data atlas could be developed in conjunction with existing public or private activities, including an assessment of the tradeoffs associated with housing the atlas inside or outside of state government.\n",
      "(6) Consultation with a broad spectrum of health care stakeholders and experts, including, but not limited to, representatives of purchasers, such as organized labor, consumers, and businesses.\n",
      "(b) The agency may enter into contracts or agreements to conduct the research described in subdivision (a).\n",
      "(c) (1) The agency shall make the results of the research described in subdivision (a) available to the public no later than March 1, 2017, by submitting a report to the Assembly and Senate Committees on Health.\n",
      "(2) Pursuant to Section 10231.5 of the Government Code, this subdivision shall become inoperative on January 1, 2021.\n",
      "(d) The agency may use federal funds for the purpose of this section.\n",
      "\n",
      "\n",
      "\n",
      "summary \n",
      " Existing law establishes health care coverage programs to provide health care to segments of the population meeting specified criteria who are otherwise unable to afford health care coverage and provides for the licensure and regulation of health insurers and health care service plans.\n",
      "This bill would require the California Health and Human Services Agency to research the options for developing a cost, quality, and equity data atlas. The bill would require the research to include certain topics, including, among others, identification of key data submitters and a comparative analysis of potential models used in other states. The bill would authorize the agency to enter into contracts or agreements to conduct the research and would require the agency to make the results of the research available to the public no later than March 1, 2017, by submitting a report to the Assembly and Senate Committees on Health.\n",
      "\n",
      "\n",
      "\n",
      "title \n",
      " An act to add Chapter 8 (commencing with Section 127670) to Part 2 of Division 107 of, and to repeal the heading of Chapter 8 (formerly commencing with Section 127670) of Part 2 of Division 107 of, the Health and Safety Code, relating to health care.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "billsum = load_dataset(\"billsum\", split=\"ca_test\")\n",
    "billsum = billsum.train_test_split(test_size=0.2)\n",
    "example = billsum[\"train\"][0]\n",
    "for key in example.keys():\n",
    "    print(key, '\\n', example[key])\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(data):\n",
    "    inputs = [\"summarize: \" + doc for doc in data[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "    labels = tokenizer(data[\"summary\"], max_length=128, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e323e709349c4d87b2114b315ad8c38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/989 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2e2a634e5d4cab8bb41831eff16a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 989\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 248\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_billsum = billsum.map(preprocess_text, batched=True, remove_columns=billsum[\"train\"].column_names)\n",
    "tokenized_billsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 989\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n",
      "  Number of trainable parameters = 60506624\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f52a22a918144f8971d4ff882677393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 248\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ebae9410894833a0d80b83b11add30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.187960624694824, 'eval_rouge1': 0.1926, 'eval_rouge2': 0.0959, 'eval_rougeL': 0.1635, 'eval_rougeLsum': 0.1639, 'eval_runtime': 386.4739, 'eval_samples_per_second': 0.642, 'eval_steps_per_second': 0.041, 'epoch': 1.0}\n",
      "{'train_runtime': 2790.8764, 'train_samples_per_second': 0.354, 'train_steps_per_second': 0.022, 'train_loss': 2.519801478232107, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=62, training_loss=2.519801478232107, metrics={'train_runtime': 2790.8764, 'train_samples_per_second': 0.354, 'train_steps_per_second': 0.022, 'train_loss': 2.519801478232107, 'epoch': 1.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./summary\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    ")\n",
    "trainer = Seq2SeqTrainer(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_billsum[\"train\"],\n",
    "    eval_dataset=tokenized_billsum[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs. It's the most aggressive action on tackling the climate crisis in American history, which will lift up American workers and create good-paying, union jobs across the country. This bill would ask the ultra-wealthy and corporations to pay their fair share.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_ids = model.generate(tokenized_text,\n",
    "                             num_beams=4, no_repeat_ngram_size=3,\n",
    "                             min_length=30, max_length=100, early_stopping=True)\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"디아블로는 액션 롤플레잉 핵 앤드 슬래시 비디오 게임이다. \n",
    "플레이어는 주변 환경을 마우스로 사용해 영웅을 움직이게 한다. \n",
    "주문을 외는 등의 다른 활동은 키보드 입력으로 이루어진다. \n",
    "플레이어는 이 게임에서 장비를 획득하고, 주문을 배우고, 적을 쓰러뜨리며, NPC와 대화를 나눌 수 있다.\n",
    "지하 미궁은 주어진 형식이 있고 부분적으로 반복되는 형태가 존재하나 전체적으로 보면 무작위로 생성된다. \n",
    "예를 들어 지하 묘지의 경우에는 긴 복도와 닫힌 문들이 존재하고, 동굴은 좀 더 선형 형태를 띠고 있다. \n",
    "플레이어에게는 몇몇 단계에서 무작위의 퀘스트를 받는다. \n",
    "이 퀘스트는 선택적인 사항이나 플레이어의 영웅들을 성장시키거나 줄거리를 이해하는데 도움을 준다. \n",
    "그러나 맨 뒤에 두 퀘스트는 게임을 끝내기 위해 완료시켜야 한다.\"\"\"\n",
    "\n",
    "preprocess_text = text.strip().replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file tokenizer.json from cache at C:\\Users\\admin/.cache\\huggingface\\hub\\models--gogamza--kobart-summarization\\snapshots\\31f181b155a0ad74bd93bd90ee04310ff72691f4\\tokenizer.json\n",
      "loading file added_tokens.json from cache at C:\\Users\\admin/.cache\\huggingface\\hub\\models--gogamza--kobart-summarization\\snapshots\\31f181b155a0ad74bd93bd90ee04310ff72691f4\\added_tokens.json\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\admin/.cache\\huggingface\\hub\\models--gogamza--kobart-summarization\\snapshots\\31f181b155a0ad74bd93bd90ee04310ff72691f4\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\admin/.cache\\huggingface\\hub\\models--gogamza--kobart-summarization\\snapshots\\31f181b155a0ad74bd93bd90ee04310ff72691f4\\config.json\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"gogamza/kobart-summarization\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "loading configuration file config.json from cache at C:\\Users\\admin/.cache\\huggingface\\hub\\models--gogamza--kobart-summarization\\snapshots\\31f181b155a0ad74bd93bd90ee04310ff72691f4\\config.json\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\admin/.cache\\huggingface\\hub\\models--gogamza--kobart-summarization\\snapshots\\31f181b155a0ad74bd93bd90ee04310ff72691f4\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at gogamza/kobart-summarization.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-summarization')\n",
    "model = BartForConditionalGeneration.from_pretrained('gogamza/kobart-summarization')\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디아블로는 액션 롤플레잉 핵 앤드 슬래시 비디오 게임이다.\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = tokenizer.encode(preprocess_text, return_tensors=\"pt\")\n",
    "summary_ids = model.generate(tokenized_text,\n",
    "                             num_beams=4, no_repeat_ngram_size=3,\n",
    "                             min_length=10, max_length=150, early_stopping=True)\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
